##### Script for making and evaluating the final classifiers for AML subtypes #####

setwd("Documents/R_work")
library(pamr)

# First, load data generated by the script "Data for pamr":

load("GRSet_beta_datasets.Rdata")
load("AML_class_vectors.Rdata")

##### Subset the beta data for known samples #####

# Choosing the vectors for subsetting the array data (cpg.freq$index[1:x])
# Three vectors for each subtype, number of CpG sites chosen are based on the look of the curves in the cpg.freq plots
# GRSet_beta_classifierX is the data that should be used for the final training with pamr.train

GRSet_beta_classifier1.t821 <- GRSet_beta_known[cpg.freq.t821.new$index[1:5], ]
GRSet_beta_classifier2.t821 <- GRSet_beta_known[cpg.freq.t821.new$index[1:12], ]
GRSet_beta_classifier3.t821 <- GRSet_beta_known[cpg.freq.t821.new$index[1:18], ]

GRSet_beta_classifier1.inv16 <- GRSet_beta_known[cpg.freq.inv16.new$index[1:6], ] # Tested 6, 7, 11 sites; 6 was best!
GRSet_beta_classifier2.inv16 <- GRSet_beta_known[cpg.freq.inv16.new$index[1:17], ]
GRSet_beta_classifier3.inv16 <- GRSet_beta_known[cpg.freq.inv16.new$index[1:79], ]

GRSet_beta_classifier1.mono7 <- GRSet_beta_known[cpg.freq.mono7.new$index[1:5], ]
GRSet_beta_classifier2.mono7 <- GRSet_beta_known[cpg.freq.mono7.new$index[1:13], ]
GRSet_beta_classifier3.mono7 <- GRSet_beta_known[cpg.freq.mono7.new$index[1:19], ]

GRSet_beta_classifier1.MLL <- GRSet_beta_known[cpg.freq.MLL.new$index[1:13], ]
GRSet_beta_classifier2.MLL <- GRSet_beta_known[cpg.freq.MLL.new$index[1:27], ]
GRSet_beta_classifier3.MLL <- GRSet_beta_known[cpg.freq.MLL.new$index[1:89], ]

# Make lists that will be input for pamr.train, making these final classifiers

t821.classifier1.list <- list(x = GRSet_beta_classifier1.t821, y = t821_class_vector)
t821.classifier2.list <- list(x = GRSet_beta_classifier2.t821, y = t821_class_vector)
t821.classifier3.list <- list(x = GRSet_beta_classifier3.t821, y = t821_class_vector)

inv16.classifier1.list <- list(x = GRSet_beta_classifier1.inv16, y = inv16_class_vector)
inv16.classifier2.list <- list(x = GRSet_beta_classifier2.inv16, y = inv16_class_vector)
inv16.classifier3.list <- list(x = GRSet_beta_classifier3.inv16, y = inv16_class_vector)

mono7.classifier1.list <- list(x = GRSet_beta_classifier1.mono7, y = mono7_class_vector)
mono7.classifier2.list <- list(x = GRSet_beta_classifier2.mono7, y = mono7_class_vector)
mono7.classifier3.list <- list(x = GRSet_beta_classifier3.mono7, y = mono7_class_vector)

MLL.classifier1.list <- list(x = GRSet_beta_classifier1.MLL, y = MLL_class_vector)
MLL.classifier2.list <- list(x = GRSet_beta_classifier2.MLL, y = MLL_class_vector)
MLL.classifier3.list <- list(x = GRSet_beta_classifier3.MLL, y = MLL_class_vector)

# Make list of all these lists to be able to use with later scripts

final.classifiers.list <- list(t821.classifier1.list, t821.classifier2.list, t821.classifier3.list, inv16.classifier1.list, inv16.classifier2.list, inv16.classifier3.list, mono7.classifier1.list, mono7.classifier2.list, mono7.classifier3.list, MLL.classifier1.list, MLL.classifier2.list, MLL.classifier3.list)

##### Functions for training the final classifiers and getting the error rates #####

get.error <- function(cv.results) {
  ncpgs <- cv.results$size[1] # Include all cpg sites!
  all_errors <- which(cv.results$size == cv.results$size[1]) # gives all indices for the rows with max nr cpgs
  max.error <- cv.results$error[which.max(cv.results$error[all_errors])] # gives the error rate for the index of the highest error
  return(max.error)
}

train.and.evaluate.final <- function(error.rate.final, classifier.list) {
  trained.data <- pamr.train(classifier.list)
  cv.results <- pamr.cv(trained.data, classifier.list)
  error <- get.error(cv.results)
  result <- list(trained.data = trained.data, error = error)
  return(result)
}

##### Loop for training the final classifiers and getting the error rates #####

# Since the pamr.train function used will be randomized it will not give the same result each time. 
# Therefore, train the classifiers 50 or 200 times and investigate the distribution of error rates for the triplets of classifiers

acc.errors <- c(0,0,0,0,0,0,0,0,0,0,0,0) # Initiate vector for storing the accumulative errors found when training the final classifiers

for (i in c(1:200)) {
  error.rate.final <- vector() # Initiate vector for storing error rates
  for (j in c(1:length(final.classifiers.list))) {
    classifier.and.error <- train.and.evaluate.final(error.rate.final, final.classifiers.list[[j]])
    #classifier.data <- classifier.and.error$trained.data
    #classifier.data.list[[j]] <- classifier.data
    #assign(paste0("classifier.data", ".", i), classifier.data) # classifier.data.X will be the classifier data for element X in final.classifiers.list
    error.rate.final[j] <- classifier.and.error$error*77 # Mult. with no of samples to get the actual number of errors
  }
  acc.errors <- acc.errors + error.rate.final
}

# Result:
#> acc.errors
#[1]   0   0   0  14  31  39  33   0   0 124 152 158      Using 6 sites for small inv16, 50 runs

#> acc.errors
#[1]   0   0   0  55 124 141 118   0   0 485 601 623      Using 6 sites for small inv16, 200 runs
#> acc.errors/4
#[1]   0.00   0.00   0.00  13.75  31.00  35.25  29.50   0.00   0.00 121.25 150.25 155.75

#> acc.errors
#[1]   0   0   0  32  29  42  35   0   0 123 151 154      Using 11 sites for small inv16, 50 runs

#> acc.errors
#[1]   0   0   0 162 127 152 106   0   0 499 607 620      Using 11 sites for small inv16, 200 runs
#> acc.errors/4
#[1]   0.00   0.00   0.00  40.50  31.75  38.00  26.50   0.00   0.00 124.75 151.75 155.00

#> acc.errors
#[1]   0   0   0 142 125 131 110   0   0 478 610 624      Using 7 sites for small inv16, 200 runs
#> acc.errors/4
#[1]   0.00   0.00   0.00  35.50  31.25  32.75  27.50   0.00   0.00 119.50 152.50 156.00

# Final errors, 200 runs, 6 sites in small inv16:

#> acc.errors
#[1]   0   0   0  69 122 140 108   0   0 487 602 621
#> acc.errors/4
#[1]   0.00   0.00   0.00  17.25  30.50  35.00  27.00   0.00   0.00 121.75 150.50 155.25

save(acc.errors, file = "accumulative_errors.Rdata")

# Make figure for this data, did in MS Excel!

# Choose the final classifiers based on this:

# t821  - classifier 3 (classifier.data.3)    Based on 18 cpg sites
# inv16 - classifier 1 (classifier.data.4)    Based on 6 cpg sites
# mono7 - classifier 3 (classifier.data.9)    Based on 19 cpg sites
# MLL   - classifier 1 (classifier.data.10)   Based on 13 cpg sites

# Run the inner loop again to generate the classifier.data variables and store them in a list
# Check that the error rates for the run corresponds to the acc.errors above, that they show the same pattern

j <- 1

for (j in c(1:length(final.classifiers.list))) {
  classifier.and.error <- train.and.evaluate.final(error.rate.final, final.classifiers.list[[j]])
  classifier.data <- classifier.and.error$trained.data
  assign(paste0("classifier.data", ".", j), classifier.data) # classifier.data.X will be the classifier data for element X in final.classifiers.list
  error.rate.final[j] <- classifier.and.error$error*77 # Mult. with no of samples to get the actual number of errors
}

#> error.rate.final
#[1] 0 0 0 0 1 1 1 0 0 2 3 4

classifier.data.t821 <- classifier.data.3
classifier.data.inv16 <- classifier.data.4
classifier.data.mono7 <- classifier.data.9
classifier.data.MLL <- classifier.data.10

save(classifier.data.t821, classifier.data.inv16, classifier.data.mono7, classifier.data.MLL, file = "final_classifiers.Rdata")

